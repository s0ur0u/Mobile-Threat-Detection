# -*- coding: utf-8 -*-
"""Mobile Threat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ufj4PTQgOCYho1zFH2qfwTbO8NUzq6Zu
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.preprocessing import RobustScaler
from sklearn import metrics
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import euclidean_distances
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import accuracy_score, recall_score, precision_score
from sklearn.datasets import fetch_openml
from sklearn.metrics.pairwise import rbf_kernel
from sklearn.linear_model import RidgeClassifierCV
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier

data= pd.read_csv("drebin215dataset5560malware9476benign.csv")

data

data.info()

missing_values = data.isnull().sum()
print(missing_values)

data=data.replace('[?]',np.NaN,regex=True)
print("Total missing values : ",sum(list(data.isna().sum())))

data.dropna(inplace=True)

print("Total missing values : ",sum(list(data.isna().sum())))

missing_values = data.isnull().sum()
print(missing_values)

class_counts = data['Class'].value_counts()
plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%')
plt.title("Class Distribution")
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.show()

data_types = data.dtypes
# Filter features with object data type
object_features = data_types[data_types == 'object'].index

# Print the features with object data type
print(object_features)

data_class = data.Class.map(lambda a: 0 if a == 'B' else 1)
data['Class'] = data_class

data['TelephonyManager.getSimCountryIso'] = data['TelephonyManager.getSimCountryIso'].astype(int)

data_types = data.dtypes
# Filter features with object data type
object_features = data_types[data_types == 'object'].index

# Print the features with object data type
print(object_features)

data

print("Total Features : ",len(data.columns)-1)

data.Class.value_counts(normalize=True)

columns = data.columns.tolist()
corr = data.corr()
correlated_vars = []
for i in range(len(columns) - 1):
    for j in range(i+1, len(columns)):
        if corr[columns[i]][columns[j]] > 0.98:
            print(columns[i], columns[j], corr[columns[i]][columns[j]])
            correlated_vars.append(columns[j])

sns.heatmap(data.corr())
plt.show()

X = data.drop(["Class"], axis=1)
y = data["Class"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)

print("Training dataset shape:", X_train.shape, y_train.shape)
print("Testing dataset shape:", X_test.shape, y_test.shape)

y_train = pd.Series(y_train)
y_test = pd.Series(y_test)

Y_train = y_train.values
Y_test = y_test.values

data.info()

Y_train = Y_train.reshape((-1,1))
Y_test = Y_test.reshape((-1,1))

print("Training dataset shape:", X_train.shape, Y_train.shape)
print("Testing dataset shape:", X_test.shape, Y_test.shape)

"""DEEP LEARNING ALGORITHMS

Recurent Neural Network(RNN)
"""

# Define the RNN model
RNN_model = keras.models.Sequential()
RNN_model.add(keras.layers.SimpleRNN(units=64, input_shape=(X_train.shape[1], 1)))

# Add additional layers if needed
RNN_model.add(keras.layers.Dense(32, activation='relu'))
#RNN_model.add(Dropout(0.2))
RNN_model.add(keras.layers.Dense(1, activation='sigmoid'))

# Compile the model
RNN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history_1= RNN_model.fit(X_train, Y_train, epochs=50, batch_size=128, validation_data=(X_test, Y_test))

y_pred_RNN = RNN_model.predict(X_test)
y_pred_RNN = (y_pred_RNN>0.5)

accuracy = metrics.accuracy_score(y_test,y_pred_RNN)
sensitivity = metrics.recall_score(y_test,y_pred_RNN)
precision = metrics.precision_score(y_test,y_pred_RNN)
print('Accuracy    = {}'.format(np.round(accuracy,3)))
print('Sensitvity  = {}'.format(np.round(sensitivity,3)))
print('Precision   = {}'.format(np.round(precision,3)))

# Plot of accuracy vs epoch for train and test dataset
plt.plot(history_1.history['accuracy'])
plt.plot(history_1.history['val_accuracy'])
plt.title("RNN Plot of accuracy vs epoch for train and test dataset")
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

"""Radial Basis Function Networks(RBFN)"""

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Perform clustering using K-means
kmeans = KMeans(n_clusters=100, random_state=42)
kmeans.fit(X_train)
centers = kmeans.cluster_centers_

# Calculate the radial basis functions
gamma = 0.1
X_train_rbf = rbf_kernel(X_train, centers, gamma)
X_test_rbf = rbf_kernel(X_test, centers, gamma)

# Train the RBFN model
rbfn = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1])
history_2= rbfn.fit(X_train_rbf, Y_train)

# Make predictions on the test set
y_pred_RBFN = rbfn.predict(X_test_rbf)

# Calculate accuracy
accuracy = accuracy_score(Y_test, y_pred_RBFN)
sensitivity = recall_score(y_test,y_pred_RBFN)
precision = precision_score(y_test,y_pred_RBFN)
print("Accuracy:", accuracy)
print("sensitivity:", sensitivity)
print("precision:", precision)

"""Self Organizing Maps(SOM)"""

pip install minisom

pip install --upgrade numpy

from minisom import MiniSom
import numpy as np
import matplotlib.pyplot as plt

# Data Preparation
X_train_normalized = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)

# SOM Parameters
map_width = 10
map_height = 10
input_length = X_train.shape[1]
epochs = 100

X_train_normalized = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)
X_train_normalized = X_train_normalized.values  # Convert DataFrame to NumPy array

X_test_normalized = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)
X_test_normalized = X_test_normalized.values  # Convert DataFrame to NumPy array

# Initialize SOM
som = MiniSom(map_width, map_height, input_length, sigma=1.0, learning_rate=0.5)
som.random_weights_init(X_train_normalized)


# Train SOM
som.train_batch(X_train_normalized, epochs, verbose=True)

# Step 2: Assign Labels
node_labels = []
for x in X_train_normalized:
    w = som.winner(x)
    nearest_labels = Y_train[w[0] * map_width + w[1]]  # Adjust the indexing
    node_labels.append(nearest_labels)

# Step 3: Classification
predicted_labels = []
for x in X_test_normalized:
    w = som.winner(x)
    history_4= predicted_labels.append(node_labels[w[0] * map_width + w[1]])

# Step 4: Compute Metrics
accuracy = accuracy_score(Y_test, predicted_labels)
sensitivity = recall_score(Y_test,predicted_labels, zero_division=1)
precision = precision_score(Y_test, predicted_labels, zero_division=1)

print("Accuracy:", accuracy)
print("Sensitivity:", sensitivity)
print("Precision:", precision)

# Plot of accuracy vs epoch for train and test dataset
plt.plot(history_4.history['accuracy'])
plt.plot(history_4.history['val_accuracy'])
plt.title("RNN Plot of accuracy vs epoch for train and test dataset")
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

"""DrebinDNN (Deep Neural Network)"""

model = Sequential()
model.add(Dense(256, activation='relu', input_shape=(215,)))
model.add(Dense(128, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Step 3: Compile and Train the Model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history_4= model.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=1, validation_data=(X_test, Y_test))

# Step 4: Evaluate the Model
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(Y_test, y_pred)
precision = precision_score(Y_test, y_pred)
sensitivity = recall_score(Y_test,y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Sensitivity:", sensitivity)

# Plot of accuracy vs epoch for train and test dataset
plt.plot(history_4.history['accuracy'])
plt.plot(history_4.history['val_accuracy'])
plt.title("DrebinDNN Plot of accuracy vs epoch for train and test dataset")
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train', 'Test'], loc='lower right')

plt.show()

"""Simple Machine Learning Algorithms"""

#Random Forest (RF)
clf=RandomForestClassifier(n_estimators=100)
clf.fit(X_train,Y_train)
y_pred_RF=clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_RF))
print("Sensitivity:",metrics.recall_score(Y_test, y_pred_RF))
print("Precision:",metrics.precision_score(Y_test, y_pred_RF))

#Support Machine Vector(SVM)
lin_svc = svm.LinearSVC().fit(X_train, Y_train)
y_pred_SVM=lin_svc.predict(X_test)
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_SVM))
print("Sensitivity:",metrics.recall_score(Y_test, y_pred_SVM))
print("Precision:",metrics.precision_score(Y_test, y_pred_SVM))

#Naive Bayes
gnb = GaussianNB().fit(X_train, Y_train)
y_pred_NB=gnb.predict(X_test)
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_NB))
print("Sensitivity:",metrics.recall_score(Y_test, y_pred_NB))
print("Precision:",metrics.precision_score(Y_test, y_pred_NB))

#Decision Tree
dt = DecisionTreeClassifier().fit(X_train, Y_train)
y_pred_DT=dt.predict(X_test)
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_DT))
print("Sensitivity:",metrics.recall_score(Y_test, y_pred_DT))
print("Precision:",metrics.precision_score(Y_test, y_pred_DT))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Define the LSTM model
LSTM_model = Sequential([
    LSTM(units=256, activation='relu', input_shape=((215,1))),
    Dense(128, activation='relu'),
    Dense(units=1, activation='sigmoid')
])

# Compile the model
LSTM_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
LSTM_history=LSTM_model.fit(X_train, y_train, validation_data=(X_test, Y_test), verbose=1, epochs=5, batch_size=32)

# Evaluate the model
test_loss, test_accuracy = LSTM_model.evaluate(X_test, Y_test)
print(f'Test Accuracy: {test_accuracy}')

from keras.callbacks import History
kernel_size = 5
filters = 64
pool_size = 4

# LSTM
lstm_output_size = 70

# Training
batch_size = 30
epochs = 2

X_train = np.array(X_train)
X_test = np.array(X_test)
#cnn-input
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
#lstm-input

Y_train = np.array(Y_train)

CNN_LSTM_model = Sequential() # initializing model
#lstm
# cnn-lstm
CNN_LSTM_model.add(Conv1D(32, 9, padding="same",input_shape = (X_train.shape[1], 1), activation='relu'))
CNN_LSTM_model.add(MaxPool1D(pool_size=(2)))
CNN_LSTM_model.add(LSTM(units=16,return_sequences=False,dropout=0.2))
CNN_LSTM_model.add(Dense(units=1))

CNN_LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history= CNN_LSTM_model.fit(X_train, Y_train, epochs=100, batch_size=250, validation_data=(X_test, Y_test))

import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout,BatchNormalization
from tensorflow.keras import regularizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler

def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

lr_scheduler = LearningRateScheduler(scheduler)

# Define a callback to adjust learning rate
#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)


# Define the RNN model
RNN_model = keras.models.Sequential()
# Input layer
RNN_model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],1), kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.01)))

# Hidden layers
RNN_model.add(Dropout(0.2))
RNN_model.add(Dense(units=32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))

# More hidden layers
RNN_model.add(BatchNormalization())
RNN_model.add(Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))

# Output layer
RNN_model.add(Dense(units=1, activation='softmax'))

# Compile the model
#RNN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Adjust learning rate in model compilation
RNN_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['accuracy'])

# Train the model
#history_1= RNN_model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_val, y_val))
history = RNN_model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test), callbacks=[lr_scheduler])